{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d37f9da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:41:48.267175Z",
     "iopub.status.busy": "2022-07-28T07:41:48.265819Z",
     "iopub.status.idle": "2022-07-28T07:42:08.520211Z",
     "shell.execute_reply": "2022-07-28T07:42:08.519626Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef4d1cea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:08.524501Z",
     "iopub.status.busy": "2022-07-28T07:42:08.523902Z",
     "iopub.status.idle": "2022-07-28T07:42:14.736000Z",
     "shell.execute_reply": "2022-07-28T07:42:14.735104Z"
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4e61b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:14.741030Z",
     "iopub.status.busy": "2022-07-28T07:42:14.740411Z",
     "iopub.status.idle": "2022-07-28T07:42:15.269159Z",
     "shell.execute_reply": "2022-07-28T07:42:15.269631Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3_utils import *\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "db = boto3.client(\"dynamodb\")\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "sfn = boto3.client(\"stepfunctions\")\n",
    "ssm_client = boto3.client('ssm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5993b55c",
   "metadata": {},
   "source": [
    "# [Custom] AWS Resource Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "056055b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:15.274033Z",
     "iopub.status.busy": "2022-07-28T07:42:15.273470Z",
     "iopub.status.idle": "2022-07-28T07:42:15.275765Z",
     "shell.execute_reply": "2022-07-28T07:42:15.275274Z"
    }
   },
   "outputs": [],
   "source": [
    "REGION = \"ap-southeast-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ffde4eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:15.280486Z",
     "iopub.status.busy": "2022-07-28T07:42:15.279248Z",
     "iopub.status.idle": "2022-07-28T07:42:15.281103Z",
     "shell.execute_reply": "2022-07-28T07:42:15.281567Z"
    }
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = ssm_client.get_parameter(Name='ngwaf_bucket_name', WithDecryption=False)['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8541ad69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:15.286243Z",
     "iopub.status.busy": "2022-07-28T07:42:15.284986Z",
     "iopub.status.idle": "2022-07-28T07:42:15.286857Z",
     "shell.execute_reply": "2022-07-28T07:42:15.287314Z"
    }
   },
   "outputs": [],
   "source": [
    "DYNAMO_NAME = ssm_client.get_parameter(Name='ngwaf_dynamodb_table_name', WithDecryption=False)['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0da460be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:15.291723Z",
     "iopub.status.busy": "2022-07-28T07:42:15.290754Z",
     "iopub.status.idle": "2022-07-28T07:42:15.292826Z",
     "shell.execute_reply": "2022-07-28T07:42:15.293301Z"
    }
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_INSTANCE_NAME = ssm_client.get_parameter(Name='ngwaf_notebook_name', WithDecryption=False)['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50bfe251",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = ssm_client.get_parameter(Name='ngwaf_endpoint_name', WithDecryption=False)['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c1f106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_FUNCTION_ARN = ssm_client.get_parameter(Name='ngwaf_state_machine_arn', WithDecryption=False)['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f7f1f7",
   "metadata": {},
   "source": [
    "### DynamoDB Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc70d3d",
   "metadata": {},
   "source": [
    "For logging of training jobs:\n",
    "1. User clicks on \"train\" with a selected dataset\n",
    "    - Post to Train API with dataset location in S3\n",
    "    - Lambda will:\n",
    "        - Check that there's no pipeline status: Query `job_key=PIPELINE_STATUS` on Dynamo\n",
    "        - Start a new training job: Add new item\n",
    "            - job_key = `new_job`\n",
    "            - status = `training`\n",
    "        - Update `PIPELINE_STATUS` to busy with job_key\n",
    "        - Move dataset into `{BUCKET}/_tmp_train` as `data.csv`\n",
    "        - Trigger notebook bootup\n",
    "2. At the end of this notebook:\n",
    "    - Update `new_job` item with status `success`\n",
    "    - Update `pipeline` status to available\n",
    "3. If the notebook fails, will be handled in `autostop.py` which runs after notebook has been idle for 5 mins:\n",
    "    - Will check if the `new_job` status is success. If not, will update `new_job` with status `failure` and update `PIPELINE_STATUS` to available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9913235e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:15.298382Z",
     "iopub.status.busy": "2022-07-28T07:42:15.297095Z",
     "iopub.status.idle": "2022-07-28T07:42:15.299018Z",
     "shell.execute_reply": "2022-07-28T07:42:15.299493Z"
    }
   },
   "outputs": [],
   "source": [
    "START_TRAIN_TIME = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413280a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:15.307392Z",
     "iopub.status.busy": "2022-07-28T07:42:15.306827Z",
     "iopub.status.idle": "2022-07-28T07:42:15.352890Z",
     "shell.execute_reply": "2022-07-28T07:42:15.353362Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the key of the current job in the pipeline\n",
    "current_job_key = db.get_item(\n",
    "    TableName=DYNAMO_NAME,\n",
    "    Key={\"job_key\": {\"S\":\"_pipeline_status\"}}\n",
    ")[\"Item\"][\"pipeline_job_key\"][\"S\"]\n",
    "current_job_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5b3f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:15.359550Z",
     "iopub.status.busy": "2022-07-28T07:42:15.358272Z",
     "iopub.status.idle": "2022-07-28T07:42:15.360167Z",
     "shell.execute_reply": "2022-07-28T07:42:15.360663Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logging broad steps to dynamoDB, can help with debugging when job fails\n",
    "def update_db_step_status(status_str, job_key=current_job_key, table_name=DYNAMO_NAME):\n",
    "    db.update_item(\n",
    "        TableName=table_name,\n",
    "        Key={\"job_key\": {\"S\": job_key}},\n",
    "        AttributeUpdates={\"step_status\": {\"Value\": {\"S\": status_str}, \"Action\": \"PUT\"}}\n",
    "    )\n",
    "    print(f\"Updated dynamo entry step_status to `{status_str}` for key `{job_key}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ad8b4",
   "metadata": {},
   "source": [
    "### Find pre-trained models\n",
    "The **keras** models are stored in the `model.tar.gz` files. \n",
    "- Need to unzip them, and then take out the `keras/` folder\n",
    "    - The other folder (`0001`) is the Tensorflow Serving model (Tensorflow SavedModel format) which is used to deploy Sagemaker endpoints. SavedModel cannot be used to reload/retrain keras models with the architecture inplace.\n",
    "- Put the entire (unzipped) folder into `{BUCKET_NAME}/_tmp_train` so it can be used in the training container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ce28e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T06:58:21.997771Z",
     "iopub.status.busy": "2022-07-21T06:58:21.948448Z",
     "iopub.status.idle": "2022-07-21T06:58:22.032200Z",
     "shell.execute_reply": "2022-07-21T06:58:22.032683Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.system(\"mkdir _tmp\")  # at clean up we delete everything\n",
    "os.mkdir(\"_tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ce6db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:15.416324Z",
     "iopub.status.busy": "2022-07-28T07:42:15.415743Z",
     "iopub.status.idle": "2022-07-28T07:42:15.418546Z",
     "shell.execute_reply": "2022-07-28T07:42:15.418019Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # TEMP\n",
    "# # Manually set the latest_model to be the pretrained model\n",
    "# baseline_path = \"base_model/kaggle_model_test_keras.tar.gz\"\n",
    "\n",
    "# # Download the tar.gz file to local\n",
    "# with open('_tmp/pretrained_model.tar.gz', 'wb') as data_file:\n",
    "#     s3.download_fileobj(BUCKET_NAME, baseline_path, data_file)\n",
    "\n",
    "# # Unzip the tar. Will create `0001` folder (tensorflow serving) and `keras` (what we want) folder\n",
    "# os.system(\"tar -xf _tmp/pretrained_model.tar.gz -C _tmp\")\n",
    "\n",
    "# # Upload the keras folder to s3\n",
    "# sess.upload_data(path=\"./_tmp/keras_model_kaggle\", bucket=BUCKET_NAME, key_prefix=\"_tmp_train/pretrained_keras\")\n",
    "    \n",
    "# pretrained = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8ad2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:15.429219Z",
     "iopub.status.busy": "2022-07-28T07:42:15.428597Z",
     "iopub.status.idle": "2022-07-28T07:42:17.474904Z",
     "shell.execute_reply": "2022-07-28T07:42:17.475351Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_objects = s3.list_objects(Bucket=BUCKET_NAME, Prefix=\"model\")['Contents']\n",
    "pretrained = 0\n",
    "\n",
    "# Find all model files \n",
    "model_files = []\n",
    "for item in model_objects:\n",
    "    if 'model.tar.gz' in item['Key']:\n",
    "        model_files.append(item)\n",
    "\n",
    "# Find latest and copy over\n",
    "if len(model_files):\n",
    "    sorted_models = sorted(model_files, key=lambda x: x['LastModified'], reverse=True)\n",
    "    latest_model = sorted_models[0]\n",
    "    print(f\"latest model path = {latest_model['Key']}\")\n",
    "    \n",
    "    # Set pretrained_flag\n",
    "    pretrained = 1\n",
    "    \n",
    "    # Download the tar.gz file to local\n",
    "    with open('_tmp/pretrained_model.tar.gz', 'wb') as data_file:\n",
    "        s3.download_fileobj(BUCKET_NAME, latest_model['Key'], data_file)\n",
    "    print(\"downloaded latest model to local\")\n",
    "        \n",
    "    # Unzip the tar. Will create `0001` folder (tensorflow serving) and `keras` (what we want) folder\n",
    "    os.system(\"tar -xf _tmp/pretrained_model.tar.gz -C _tmp\")\n",
    "    print(\"Unzipped the tar\")\n",
    "    \n",
    "    # Upload the keras folder to s3\n",
    "    sess.upload_data(path=\"./_tmp/keras\", bucket=BUCKET_NAME, key_prefix=\"_tmp_train/pretrained_keras\")\n",
    "    print(\"Uploaded keras version of the model to _tmp_train in S3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f8559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:17.481606Z",
     "iopub.status.busy": "2022-07-28T07:42:17.480744Z",
     "iopub.status.idle": "2022-07-28T07:42:17.492822Z",
     "shell.execute_reply": "2022-07-28T07:42:17.493658Z"
    }
   },
   "outputs": [],
   "source": [
    "if pretrained == 1:\n",
    "    update_db_step_status(\"pretrained model loaded\")\n",
    "else:\n",
    "    update_db_step_status(\"no pretrained model found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478119c7",
   "metadata": {},
   "source": [
    "### Split into training & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee7a566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:17.498864Z",
     "iopub.status.busy": "2022-07-28T07:42:17.498305Z",
     "iopub.status.idle": "2022-07-28T07:42:17.501643Z",
     "shell.execute_reply": "2022-07-28T07:42:17.502075Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(data, train_pct, val_pct, test_pct):\n",
    "    testval_frac = test_pct / (val_pct + test_pct)\n",
    "\n",
    "    train, testval = train_test_split(data, test_size=(val_pct + test_pct), random_state=42)\n",
    "    val, test = train_test_split(testval, test_size=testval_frac, random_state=42)\n",
    "\n",
    "    return (train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66816b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:17.506379Z",
     "iopub.status.busy": "2022-07-28T07:42:17.505803Z",
     "iopub.status.idle": "2022-07-28T07:42:17.509430Z",
     "shell.execute_reply": "2022-07-28T07:42:17.509923Z"
    }
   },
   "outputs": [],
   "source": [
    "# # TEMP: To copy from the train bucket into the sgaemaker bucket. Usually will be handled by lambda.\n",
    "# s3.copy_object(\n",
    "#     CopySource=\"ngwaf-trainbucket/kaggle_v2_finetune_data.csv\",\n",
    "#     Bucket=BUCKET_NAME,\n",
    "#     Key=\"_tmp_train/data.csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c25e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:17.515375Z",
     "iopub.status.busy": "2022-07-28T07:42:17.514544Z",
     "iopub.status.idle": "2022-07-28T07:42:17.651246Z",
     "shell.execute_reply": "2022-07-28T07:42:17.650371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the data from S3\n",
    "with open('_tmp/data.csv', 'wb') as data_file:\n",
    "    s3.download_fileobj(BUCKET_NAME, '_tmp_train/data.csv', data_file)\n",
    "\n",
    "# Split the data\n",
    "data = pd.read_csv(\"_tmp/data.csv\")\n",
    "train, val, test = train_val_test_split(data, 0.6, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a18715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:17.660955Z",
     "iopub.status.busy": "2022-07-28T07:42:17.653734Z",
     "iopub.status.idle": "2022-07-28T07:42:17.860864Z",
     "shell.execute_reply": "2022-07-28T07:42:17.859951Z"
    }
   },
   "outputs": [],
   "source": [
    "write_df_to_s3(train, \"training.csv\", BUCKET_NAME, \"_tmp_train/training.csv\")\n",
    "write_df_to_s3(val, \"validation.csv\", BUCKET_NAME, \"_tmp_train/validation.csv\")\n",
    "write_df_to_s3(test, \"testing.csv\", BUCKET_NAME, \"_tmp_train/testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e33e0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:17.867087Z",
     "iopub.status.busy": "2022-07-28T07:42:17.866205Z",
     "iopub.status.idle": "2022-07-28T07:42:17.877597Z",
     "shell.execute_reply": "2022-07-28T07:42:17.878050Z"
    }
   },
   "outputs": [],
   "source": [
    "update_db_step_status(\"train/test/val data uploaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bc644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:17.881959Z",
     "iopub.status.busy": "2022-07-28T07:42:17.881388Z",
     "iopub.status.idle": "2022-07-28T07:42:27.892211Z",
     "shell.execute_reply": "2022-07-28T07:42:27.892697Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sleep a bit to make sure stuff is uploaded\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915136a",
   "metadata": {},
   "source": [
    "### Specify parameters & train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd4b85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:27.899534Z",
     "iopub.status.busy": "2022-07-28T07:42:27.898938Z",
     "iopub.status.idle": "2022-07-28T07:42:27.901655Z",
     "shell.execute_reply": "2022-07-28T07:42:27.901074Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_FILE = 'model_v2.py'\n",
    "MODEL_SOURCE_DIR = \"script\"\n",
    "FRAMEWORK_VERSION = \"2.8\"  # tensorflow version\n",
    "\n",
    "# Training params, can increase for production\n",
    "# In the future, can move definition into the API call/dynamo entry\n",
    "# INSTANCE_TYPE = \"local\"1\n",
    "INSTANCE_TYPE = \"ml.m5.large\"\n",
    "INSTANCE_COUNT = 1\n",
    "N_EPOCHS = 20\n",
    "PATIENCE = 3\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# For logging\n",
    "VERSION_NAME = \"tensorflow-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "VERSION_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1061fec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:27.907512Z",
     "iopub.status.busy": "2022-07-28T07:42:27.906318Z",
     "iopub.status.idle": "2022-07-28T07:42:27.923530Z",
     "shell.execute_reply": "2022-07-28T07:42:27.922653Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point=MODEL_FILE, \n",
    "                          source_dir=MODEL_SOURCE_DIR,\n",
    "                          role=role,\n",
    "                          #model_dir=MODEL_DIR, # this only saves the checkpoints \n",
    "                          instance_count=INSTANCE_COUNT, \n",
    "                          instance_type=INSTANCE_TYPE,\n",
    "                          framework_version=FRAMEWORK_VERSION,\n",
    "                          py_version='py39',\n",
    "                          script_mode=True,\n",
    "                          hyperparameters={\n",
    "                              \"epochs\": N_EPOCHS,\n",
    "                              \"batch_size\": BATCH_SIZE,\n",
    "                              \"early_stop_patience\": PATIENCE, \n",
    "                              \"pretrained\": pretrained,\n",
    "                              \"region\": REGION,\n",
    "                              \"db_name\": DYNAMO_NAME,\n",
    "                              \"job_key\": current_job_key\n",
    "                          },\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b2804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:27.929263Z",
     "iopub.status.busy": "2022-07-28T07:42:27.928403Z",
     "iopub.status.idle": "2022-07-28T07:42:27.938582Z",
     "shell.execute_reply": "2022-07-28T07:42:27.937687Z"
    }
   },
   "outputs": [],
   "source": [
    "update_db_step_status(\"launching tensorflow training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68fe85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:42:27.942738Z",
     "iopub.status.busy": "2022-07-28T07:42:27.942174Z",
     "iopub.status.idle": "2022-07-28T07:50:38.470171Z",
     "shell.execute_reply": "2022-07-28T07:50:38.469688Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_estimator.fit(f\"s3://{BUCKET_NAME}/_tmp_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff3005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:38.476000Z",
     "iopub.status.busy": "2022-07-28T07:50:38.475430Z",
     "iopub.status.idle": "2022-07-28T07:50:38.480981Z",
     "shell.execute_reply": "2022-07-28T07:50:38.480488Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd5cf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:38.486771Z",
     "iopub.status.busy": "2022-07-28T07:50:38.486211Z",
     "iopub.status.idle": "2022-07-28T07:50:38.534007Z",
     "shell.execute_reply": "2022-07-28T07:50:38.533537Z"
    }
   },
   "outputs": [],
   "source": [
    "update_db_step_status(\"exited tensorflow training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46c469e",
   "metadata": {},
   "source": [
    "### Copy objects from sagemaker bucket to main bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4913b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:38.542440Z",
     "iopub.status.busy": "2022-07-28T07:50:38.541840Z",
     "iopub.status.idle": "2022-07-28T07:50:39.172187Z",
     "shell.execute_reply": "2022-07-28T07:50:39.172715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the directory that sagemaker saved it in\n",
    "# s3://sagemaker-ap-southeast-1-000394774158/tensorflow-training-2022-09-18-09-07-25-649/output/model.tar.gz' \n",
    "# Directory changed when using sagemaker training jobs\n",
    "sm_model_bucket, sm_model_prefix, _ = tf_estimator.model_data.replace(\"/model.tar.gz\", \"\").replace(\"s3://\", \"\").split(\"/\")\n",
    "\n",
    "# Get all the bucket items\n",
    "# sm_model_objects = s3.list_objects(Bucket=sm_model_bucket, Prefix=sm_model_prefix)['Contents']\n",
    "\n",
    "# Training Jobs missing other files\n",
    "# Copying the model.tar.gz\n",
    "s3.copy_object(\n",
    "    CopySource=os.path.join(sm_model_bucket, f\"{sm_model_prefix}/output/model.tar.gz\"),\n",
    "    Bucket=BUCKET_NAME,\n",
    "    Key=os.path.join(\"model\", VERSION_NAME, \"model.tar.gz\")\n",
    ")\n",
    "\n",
    "# Copy source.tar.gz\n",
    "s3.copy_object(\n",
    "    CopySource=os.path.join(sm_model_bucket, f\"{sm_model_prefix}/source/sourcedir.tar.gz\"),\n",
    "    Bucket=BUCKET_NAME,\n",
    "    Key=os.path.join(\"model\", VERSION_NAME, \"source/sourcedir.tar.gz\")\n",
    ")\n",
    "\n",
    "# for o in sm_model_objects:\n",
    "#     file_name = o[\"Key\"].split(\"/\")\n",
    "#     file_name.remove(sm_model_prefix)\n",
    "#     file_name = \"/\".join(file_name)\n",
    "#     copy_source = os.path.join(sm_model_bucket, o[\"Key\"])\n",
    "#     target_key = os.path.join(\"model\", VERSION_NAME, file_name)\n",
    "#     print(f\"Copying: {file_name}\\nfrom: {copy_source}\\nto target bucket w filename: {target_key}...\\n\")\n",
    "#     s3.copy_object(\n",
    "#         CopySource=copy_source,\n",
    "#         Bucket=BUCKET_NAME,\n",
    "#         Key=target_key\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd94af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:39.178543Z",
     "iopub.status.busy": "2022-07-28T07:50:39.177571Z",
     "iopub.status.idle": "2022-07-28T07:50:39.191530Z",
     "shell.execute_reply": "2022-07-28T07:50:39.191040Z"
    }
   },
   "outputs": [],
   "source": [
    "update_db_step_status(\"copied objects to sm bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95934128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:39.196682Z",
     "iopub.status.busy": "2022-07-28T07:50:39.196079Z",
     "iopub.status.idle": "2022-07-28T07:50:39.200386Z",
     "shell.execute_reply": "2022-07-28T07:50:39.199890Z"
    }
   },
   "outputs": [],
   "source": [
    "new_artifact_path = \"s3://\" + os.path.join(BUCKET_NAME, \"model\", VERSION_NAME, \"model.tar.gz\")\n",
    "new_artifact_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee581ec",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a976029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:39.204830Z",
     "iopub.status.busy": "2022-07-28T07:50:39.204229Z",
     "iopub.status.idle": "2022-07-28T07:50:39.207071Z",
     "shell.execute_reply": "2022-07-28T07:50:39.206510Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DEPLOYMENT_INSTANCE_TYPE = 'ml.c5.large'\n",
    "DEPLOYMENT_INSTANCE_COUNT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea68c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:39.211902Z",
     "iopub.status.busy": "2022-07-28T07:50:39.211289Z",
     "iopub.status.idle": "2022-07-28T07:50:39.215424Z",
     "shell.execute_reply": "2022-07-28T07:50:39.214763Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.tensorflow.model import TensorFlowModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d752e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:39.228608Z",
     "iopub.status.busy": "2022-07-28T07:50:39.227973Z",
     "iopub.status.idle": "2022-07-28T07:50:39.286152Z",
     "shell.execute_reply": "2022-07-28T07:50:39.285378Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if endpoint is already alive\n",
    "endpoint_exist = False\n",
    "\n",
    "endpoints = boto3.client(\"sagemaker\").list_endpoints(NameContains=ENDPOINT_NAME)\n",
    "for ep in endpoints['Endpoints']:\n",
    "    if ep['EndpointName'] == ENDPOINT_NAME:\n",
    "        endpoint_exist = True\n",
    "        break\n",
    "endpoint_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed33e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:39.292256Z",
     "iopub.status.busy": "2022-07-28T07:50:39.291691Z",
     "iopub.status.idle": "2022-07-28T07:50:39.300423Z",
     "shell.execute_reply": "2022-07-28T07:50:39.299903Z"
    }
   },
   "outputs": [],
   "source": [
    "update_db_step_status(f\"deployment. endpoint exist = {str(endpoint_exist)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80b9f4",
   "metadata": {},
   "source": [
    "If endpoint exists, then we need to\n",
    "1. First deploy as its own endpoint\n",
    "2. Then load the existing endpoint as a `Predictor`\n",
    "3. Update that predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6f3d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:39.305055Z",
     "iopub.status.busy": "2022-07-28T07:50:39.304241Z",
     "iopub.status.idle": "2022-07-28T07:50:39.309315Z",
     "shell.execute_reply": "2022-07-28T07:50:39.308026Z"
    }
   },
   "outputs": [],
   "source": [
    "from diagnostic_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991e329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:39.317528Z",
     "iopub.status.busy": "2022-07-28T07:50:39.312213Z",
     "iopub.status.idle": "2022-07-28T07:50:39.319736Z",
     "shell.execute_reply": "2022-07-28T07:50:39.320211Z"
    }
   },
   "outputs": [],
   "source": [
    "if endpoint_exist:\n",
    "    # 1. Deploy as separate instance\n",
    "    updated_model = TensorFlowModel(\n",
    "        model_data = new_artifact_path,\n",
    "        role=role,\n",
    "        framework_version=FRAMEWORK_VERSION,\n",
    "        sagemaker_session=sess,\n",
    "        name = VERSION_NAME\n",
    "    )\n",
    "    updated_predictor = updated_model.deploy(\n",
    "        initial_instance_count=DEPLOYMENT_INSTANCE_COUNT,\n",
    "        instance_type=DEPLOYMENT_INSTANCE_TYPE\n",
    "    )\n",
    "    print()\n",
    "    print(f\"New model name = {updated_model.name}\")\n",
    "    print(f\"Temporary endpoint name = {updated_predictor.endpoint_name}\")\n",
    "    \n",
    "    # 2. Save diagnostics for model performance\n",
    "    diagnostic, scores = test_diagnostics(updated_predictor, test)\n",
    "    write_df_to_s3(diagnostic, VERSION_NAME + \"_diagnostic.csv\",\n",
    "                   BUCKET_NAME, os.path.join(\"model\", VERSION_NAME, \"diagnostic.csv\"))\n",
    "    write_df_to_s3(scores, VERSION_NAME + \"_diagnostic.csv\",\n",
    "                   BUCKET_NAME, os.path.join(\"model\", VERSION_NAME, \"scores.csv\"))\n",
    "    \n",
    "    ## TODO: Only deploy if it is better\n",
    "    \n",
    "    # 3. Load existing endpoint\n",
    "    current_predictor = Predictor(\n",
    "        endpoint_name = ENDPOINT_NAME,\n",
    "        sagemaker_session=sess,\n",
    "    )\n",
    "    print(f\"Before updating, {ENDPOINT_NAME} endpoint is using model {get_model_variant(ENDPOINT_NAME)}\")\n",
    "    \n",
    "    # 4. Update endpoint\n",
    "    current_predictor.update_endpoint(\n",
    "        model_name = updated_model.name,\n",
    "        initial_instance_count = DEPLOYMENT_INSTANCE_COUNT,\n",
    "        instance_type = DEPLOYMENT_INSTANCE_TYPE\n",
    "    )\n",
    "    print()\n",
    "    print(f\"Updated: {ENDPOINT_NAME} endpoint is now using model {get_model_variant(ENDPOINT_NAME)}\")\n",
    "    \n",
    "    # 5. Delete the separate endpoint\n",
    "    temp_endpoint_name = updated_predictor.endpoint_name\n",
    "    temp_endpoint_config_name = get_config_name(temp_endpoint_name)\n",
    "\n",
    "    sess.delete_endpoint(updated_predictor.endpoint_name)\n",
    "    print(f\"Cleaned up the temporary endpoint {temp_endpoint_name}\")\n",
    "    sess.delete_endpoint_config(temp_endpoint_config_name)\n",
    "    print(f\"Cleaned up the temporary endpoint config {temp_endpoint_config_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8efd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:50:39.331387Z",
     "iopub.status.busy": "2022-07-28T07:50:39.330786Z",
     "iopub.status.idle": "2022-07-28T07:52:44.211899Z",
     "shell.execute_reply": "2022-07-28T07:52:44.212334Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not endpoint_exist:\n",
    "    serving_model = TensorFlowModel(\n",
    "        model_data = new_artifact_path,\n",
    "        role=role,\n",
    "        framework_version=FRAMEWORK_VERSION,\n",
    "        sagemaker_session=sess,\n",
    "        name=VERSION_NAME\n",
    "    )\n",
    "    \n",
    "    # Delete existing endpoint if exists\n",
    "    client = boto3.client('sagemaker')\n",
    "    try:\n",
    "        response = client.describe_endpoint_config(EndpointConfigName=ENDPOINT_NAME)\n",
    "        client.delete_endpoint_config(EndpointConfigName=ENDPOINT_NAME)        \n",
    "    except:\n",
    "        # Endpoint not exists\n",
    "        pass\n",
    "\n",
    "    predictor = serving_model.deploy(\n",
    "        initial_instance_count=DEPLOYMENT_INSTANCE_COUNT,\n",
    "        instance_type=DEPLOYMENT_INSTANCE_TYPE,\n",
    "        endpoint_name=ENDPOINT_NAME\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Diagnostics\n",
    "    diagnostic, scores = test_diagnostics(predictor, test)\n",
    "    write_df_to_s3(diagnostic, VERSION_NAME + \"_diagnostic.csv\",\n",
    "                   BUCKET_NAME, os.path.join(\"model\", VERSION_NAME, \"diagnostic.csv\"))\n",
    "    write_df_to_s3(scores, VERSION_NAME + \"_diagnostic.csv\",\n",
    "                   BUCKET_NAME, os.path.join(\"model\", VERSION_NAME, \"scores.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb21fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:52:44.217688Z",
     "iopub.status.busy": "2022-07-28T07:52:44.217122Z",
     "iopub.status.idle": "2022-07-28T07:52:44.260923Z",
     "shell.execute_reply": "2022-07-28T07:52:44.260410Z"
    }
   },
   "outputs": [],
   "source": [
    "update_db_step_status(\"endpoints deployed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4948a",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823aa49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:52:44.268290Z",
     "iopub.status.busy": "2022-07-28T07:52:44.267697Z",
     "iopub.status.idle": "2022-07-28T07:52:44.786251Z",
     "shell.execute_reply": "2022-07-28T07:52:44.786923Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete the objects in the _tmp_train bucket\n",
    "TMP_DIR = \"_tmp_train\"\n",
    "tmp_items = s3.list_objects(Bucket=BUCKET_NAME.replace(\"s3://\", \"\"), Prefix=TMP_DIR)['Contents']\n",
    "\n",
    "for item in tmp_items:\n",
    "    if item['Key'] == f\"{TMP_DIR}/\":\n",
    "        pass # ignore the common prefix\n",
    "    else:\n",
    "        s3.delete_object(\n",
    "            Bucket=BUCKET_NAME,\n",
    "            Key=item['Key']\n",
    "        )\n",
    "        print(f\"Deleted {item['Key']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d70632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:52:44.790979Z",
     "iopub.status.busy": "2022-07-28T07:52:44.790424Z",
     "iopub.status.idle": "2022-07-28T07:52:44.801825Z",
     "shell.execute_reply": "2022-07-28T07:52:44.801324Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete objects in sagemaker folder\n",
    "# os.system(\"rm -r _tmp\")\n",
    "import shutil\n",
    "shutil.rmtree(\"_tmp\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef84a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:52:44.807552Z",
     "iopub.status.busy": "2022-07-28T07:52:44.806637Z",
     "iopub.status.idle": "2022-07-28T07:52:44.816689Z",
     "shell.execute_reply": "2022-07-28T07:52:44.817162Z"
    }
   },
   "outputs": [],
   "source": [
    "update_db_step_status(\"local sagemaker directory + s3 tmp bucket cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de345746",
   "metadata": {},
   "source": [
    "### Post back to DynamoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53954b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:52:44.821572Z",
     "iopub.status.busy": "2022-07-28T07:52:44.820990Z",
     "iopub.status.idle": "2022-07-28T07:52:44.824740Z",
     "shell.execute_reply": "2022-07-28T07:52:44.824231Z"
    }
   },
   "outputs": [],
   "source": [
    "END_TRAIN_TIME = datetime.datetime.now()\n",
    "\n",
    "train_duration_secs = (END_TRAIN_TIME - START_TRAIN_TIME).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26536e29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:52:44.831779Z",
     "iopub.status.busy": "2022-07-28T07:52:44.831100Z",
     "iopub.status.idle": "2022-07-28T07:52:44.838962Z",
     "shell.execute_reply": "2022-07-28T07:52:44.839434Z"
    }
   },
   "outputs": [],
   "source": [
    "updated_attributes = {\n",
    "    \"status\": {\"Value\": {\"S\": \"success\"}, \"Action\": \"PUT\"},\n",
    "    \"training_completion_time\": {\"Value\": {\"S\": time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())},\n",
    "                                 \"Action\": \"PUT\"},\n",
    "    \"training_duration_sec\": {\"Value\": {\"N\": str(train_duration_secs)}, \"Action\": \"PUT\"},\n",
    "    \"model_name\": {\"Value\": {\"S\": VERSION_NAME}, \"Action\": \"PUT\"},\n",
    "    \"model_diagnostics\": {\n",
    "        \"Value\": build_dynamo_model_diagnostics(diagnostic),\n",
    "        \"Action\": \"PUT\"\n",
    "    },\n",
    "    \"model_performance\": {\n",
    "        \"Value\": build_dynamo_model_performance(scores),\n",
    "        \"Action\": \"PUT\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f781c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:52:44.846574Z",
     "iopub.status.busy": "2022-07-28T07:52:44.846009Z",
     "iopub.status.idle": "2022-07-28T07:52:44.851629Z",
     "shell.execute_reply": "2022-07-28T07:52:44.851143Z"
    }
   },
   "outputs": [],
   "source": [
    "updated_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d54add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:52:44.858012Z",
     "iopub.status.busy": "2022-07-28T07:52:44.857448Z",
     "iopub.status.idle": "2022-07-28T07:52:44.869478Z",
     "shell.execute_reply": "2022-07-28T07:52:44.869010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update item\n",
    "db.update_item(\n",
    "    TableName=DYNAMO_NAME,\n",
    "    Key={\"job_key\": {\"S\": current_job_key}},\n",
    "    AttributeUpdates=updated_attributes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f14196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:52:44.875724Z",
     "iopub.status.busy": "2022-07-28T07:52:44.875128Z",
     "iopub.status.idle": "2022-07-28T07:52:44.885598Z",
     "shell.execute_reply": "2022-07-28T07:52:44.885008Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update pipeline status\n",
    "db.update_item(\n",
    "    TableName=DYNAMO_NAME,\n",
    "    Key={\"job_key\": {\"S\": \"_pipeline_status\"}},\n",
    "    AttributeUpdates={\n",
    "        \"pipeline_available\": {\"Value\": {\"BOOL\": True}, \"Action\": \"PUT\"},\n",
    "        \"pipeline_job_key\": {\"Value\": {\"S\": \"\"}, \"Action\": \"PUT\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b09699d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:52:44.891197Z",
     "iopub.status.busy": "2022-07-28T07:52:44.890569Z",
     "iopub.status.idle": "2022-07-28T07:52:44.900150Z",
     "shell.execute_reply": "2022-07-28T07:52:44.899545Z"
    }
   },
   "outputs": [],
   "source": [
    "update_db_step_status(\"dynamodb updated, notebook shutting down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a623006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the step function\n",
    "\n",
    "response = sfn.list_executions(\n",
    "    stateMachineArn=STEP_FUNCTION_ARN,\n",
    "    statusFilter='RUNNING'\n",
    ")\n",
    "\n",
    "# Extract the latest one (Assuming only one can be running)\n",
    "executions = response['executions']\n",
    "\n",
    "if (len(executions) > 0):\n",
    "    execution_arn = executions[0]['executionArn']\n",
    "    sfn.stop_execution(\n",
    "        executionArn=execution_arn,\n",
    "        cause='notebook successfully completed'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37515bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T07:52:44.905816Z",
     "iopub.status.busy": "2022-07-28T07:52:44.905210Z",
     "iopub.status.idle": "2022-07-28T07:52:44.981017Z",
     "shell.execute_reply": "2022-07-28T07:52:44.980522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shutdown notebook\n",
    "sm.stop_notebook_instance(NotebookInstanceName=NOTEBOOK_INSTANCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c716a4",
   "metadata": {},
   "source": [
    "## Other notes\n",
    "### Proceed to go to `lambda` and input the endpoint name\n",
    "### Go to API Gateway and\n",
    "1. Create new API: REST method\n",
    "2. Create new method -- POST\n",
    "    - Attach the lambda you created\n",
    "    - click on the `Use Lambda Proxy integration`. This option makes sure that the data that is sent to the API is then sent directly to the Lambda function with no processing. It also means that the return value must be a proper response object as it will also not be processed by API Gateway.\n",
    "3. Click on `Actions` --> Deploy API\n",
    "4.  sure to copy or write down the URL provided to invoke your newly created public API as this will be needed in the next step. This URL can be found at the top of the page, highlighted in blue next to the text Invoke URL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
