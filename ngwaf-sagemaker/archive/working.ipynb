{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac34986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05885c04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db63711",
   "metadata": {},
   "source": [
    "## Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9ea8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-ap-southeast-1-527655063528'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = sess.default_bucket()\n",
    "prefix = \"uploads\"\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = sess.upload_data(path=\"./pretrained\", bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6018dc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-southeast-1-527655063528/uploads'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd7a404d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-ap-southeast-1-527655063528'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2e703",
   "metadata": {},
   "source": [
    "## Train on notebook instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e96e210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-10 05:21:09 sagemaker-ap-southeast-1-527655063528\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 lsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de27e9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.24.42'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import botocore\n",
    "botocore.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba38f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_directory = 's3://sagemaker-ap-southeast-1-527655063528/uploads'\n",
    "\n",
    "MODEL_FILE = 'model_v1_vect.py'\n",
    "FRAMEWORK_VERSION = \"2.8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05855faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point=MODEL_FILE, \n",
    "                          source_dir=\"script\",\n",
    "                          role=role,\n",
    "                          instance_count=1, \n",
    "                          instance_type='local',\n",
    "                          framework_version=FRAMEWORK_VERSION,\n",
    "                          py_version='py39',\n",
    "                          script_mode=True,\n",
    "                          #env={'SAGEMAKER_REQUIREMENTS': 'requirements.txt'},\n",
    "                          hyperparameters={\n",
    "                              \"epochs\": 1,\n",
    "                              \"data\": \"small_fwaf.csv\", #data_input_path,\n",
    "                              \"weights\": \"9_jun_1130am_weights\", #weights_path_main,\n",
    "                              \"vectorizer\": \"9_jun_1130am_vectorizer.pkl\", #vectorizer_path\n",
    "                          },\n",
    "#                           distribution={\"parameter_server\": {\"enabled\": True}}, # not sure what this does\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f3502a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating s7xk7bn6qm-algo-1-ka25b ... \n",
      "Creating s7xk7bn6qm-algo-1-ka25b ... done\n",
      "Attaching to s7xk7bn6qm-algo-1-ka25b\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:36.614176: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:36.614409: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:36.648254: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:38,898 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:38,909 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:39,165 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m /usr/local/bin/python3.9 -m pip install -r requirements.txt\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Collecting s3fs>=2021.04.0\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Downloading s3fs-2022.5.0-py3-none-any.whl (27 kB)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.1.0)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Collecting aiobotocore~=2.3.0\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Downloading aiobotocore-2.3.3.tar.gz (65 kB)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.7/65.7 kB 11.9 MB/s eta 0:00:00\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Preparing metadata (setup.py): started\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Preparing metadata (setup.py): finished with status 'done'\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: fsspec==2022.5.0 in /usr/local/lib/python3.9/site-packages (from s3fs>=2021.04.0->-r requirements.txt (line 1)) (2022.5.0)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Collecting aiohttp<=4\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Downloading aiohttp-3.8.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 47.7 MB/s eta 0:00:00\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Collecting botocore<1.24.22,>=1.24.21\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Downloading botocore-1.24.21-py3-none-any.whl (8.6 MB)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 52.8 MB/s eta 0:00:00\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: wrapt>=1.10.10 in /usr/local/lib/python3.9/site-packages (from aiobotocore~=2.3.0->s3fs>=2021.04.0->-r requirements.txt (line 1)) (1.14.1)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Collecting aioitertools>=0.5.1\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Downloading aioitertools-0.10.0-py3-none-any.whl (23 kB)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Collecting yarl<2.0,>=1.0\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Downloading yarl-1.7.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (304 kB)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 304.5/304.5 kB 32.0 MB/s eta 0:00:00\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Collecting frozenlist>=1.1.1\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Downloading frozenlist-1.3.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 156.2/156.2 kB 23.5 MB/s eta 0:00:00\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Collecting aiosignal>=1.1.2\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/site-packages (from aiohttp<=4->s3fs>=2021.04.0->-r requirements.txt (line 1)) (2.0.12)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Collecting multidict<7.0,>=4.5\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Downloading multidict-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.2/114.2 kB 7.0 MB/s eta 0:00:00\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Collecting async-timeout<5.0,>=4.0.0a3\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp<=4->s3fs>=2021.04.0->-r requirements.txt (line 1)) (20.3.0)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.9/site-packages (from aioitertools>=0.5.1->aiobotocore~=2.3.0->s3fs>=2021.04.0->-r requirements.txt (line 1)) (4.2.0)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/site-packages (from botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.0->s3fs>=2021.04.0->-r requirements.txt (line 1)) (1.26.9)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/site-packages (from botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.0->s3fs>=2021.04.0->-r requirements.txt (line 1)) (1.0.0)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/site-packages (from botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.0->s3fs>=2021.04.0->-r requirements.txt (line 1)) (2.8.2)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp<=4->s3fs>=2021.04.0->-r requirements.txt (line 1)) (3.3)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.0->s3fs>=2021.04.0->-r requirements.txt (line 1)) (1.16.0)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Building wheels for collected packages: aiobotocore\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Building wheel for aiobotocore (setup.py): started\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Building wheel for aiobotocore (setup.py): finished with status 'done'\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Created wheel for aiobotocore: filename=aiobotocore-2.3.3-py3-none-any.whl size=64624 sha256=67aa53f60c27e4a31f4c0c3011550e669bfee86f45d80f64edae70c786382a9a\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Stored in directory: /root/.cache/pip/wheels/94/17/78/ffd14570472cdfb16001e4a30e8c9cab25c9e22e126c58ecd1\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Successfully built aiobotocore\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Installing collected packages: multidict, frozenlist, async-timeout, aioitertools, yarl, botocore, aiosignal, aiohttp, aiobotocore, s3fs\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Attempting uninstall: botocore\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Found existing installation: botocore 1.26.4\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Uninstalling botocore-1.26.4:\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Successfully uninstalled botocore-1.26.4\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Attempting uninstall: s3fs\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Found existing installation: s3fs 0.4.2\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Uninstalling s3fs-0.4.2:\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Successfully uninstalled s3fs-0.4.2\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m boto3 1.23.4 requires botocore<1.27.0,>=1.26.4, but you have botocore 1.24.21 which is incompatible.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m awscli 1.24.4 requires botocore==1.26.4, but you have botocore 1.24.21 which is incompatible.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Successfully installed aiobotocore-2.3.3 aiohttp-3.8.1 aioitertools-0.10.0 aiosignal-1.2.0 async-timeout-4.0.2 botocore-1.24.21 frozenlist-1.3.0 multidict-6.0.2 s3fs-2022.5.0 yarl-1.7.2\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m WARNING: There was an error checking the latest version of pip.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:51,568 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:51,592 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:51,616 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:51,628 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Training Env:\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m {\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     },\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"current_host\": \"algo-1-ka25b\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"hosts\": [\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         \"algo-1-ka25b\"\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     ],\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         \"data\": \"small_fwaf.csv\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         \"weights\": \"9_jun_1130am_weights\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         \"vectorizer\": \"9_jun_1130am_vectorizer.pkl\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         \"model_dir\": \"s3://sagemaker-ap-southeast-1-527655063528/tensorflow-training-2022-06-13-06-01-31-389/model\"\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     },\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         \"training\": {\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         }\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     },\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"job_name\": \"tensorflow-training-2022-06-13-06-01-31-389\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"master_hostname\": \"algo-1-ka25b\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-southeast-1-527655063528/tensorflow-training-2022-06-13-06-01-31-389/source/sourcedir.tar.gz\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"module_name\": \"model_v1_vect\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         \"current_host\": \"algo-1-ka25b\",\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         \"hosts\": [\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m             \"algo-1-ka25b\"\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m         ]\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     },\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m     \"user_entry_point\": \"model_v1_vect.py\"\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m }\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Environment variables:\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_HOSTS=[\"algo-1-ka25b\"]\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_HPS={\"data\":\"small_fwaf.csv\",\"epochs\":1,\"model_dir\":\"s3://sagemaker-ap-southeast-1-527655063528/tensorflow-training-2022-06-13-06-01-31-389/model\",\"vectorizer\":\"9_jun_1130am_vectorizer.pkl\",\"weights\":\"9_jun_1130am_weights\"}\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_USER_ENTRY_POINT=model_v1_vect.py\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-ka25b\",\"hosts\":[\"algo-1-ka25b\"]}\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_CURRENT_HOST=algo-1-ka25b\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_MODULE_NAME=model_v1_vect\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-southeast-1-527655063528/tensorflow-training-2022-06-13-06-01-31-389/source/sourcedir.tar.gz\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-ka25b\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-ka25b\"],\"hyperparameters\":{\"data\":\"small_fwaf.csv\",\"epochs\":1,\"model_dir\":\"s3://sagemaker-ap-southeast-1-527655063528/tensorflow-training-2022-06-13-06-01-31-389/model\",\"vectorizer\":\"9_jun_1130am_vectorizer.pkl\",\"weights\":\"9_jun_1130am_weights\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2022-06-13-06-01-31-389\",\"log_level\":20,\"master_hostname\":\"algo-1-ka25b\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-527655063528/tensorflow-training-2022-06-13-06-01-31-389/source/sourcedir.tar.gz\",\"module_name\":\"model_v1_vect\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-ka25b\",\"hosts\":[\"algo-1-ka25b\"]},\"user_entry_point\":\"model_v1_vect.py\"}\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_USER_ARGS=[\"--data\",\"small_fwaf.csv\",\"--epochs\",\"1\",\"--model_dir\",\"s3://sagemaker-ap-southeast-1-527655063528/tensorflow-training-2022-06-13-06-01-31-389/model\",\"--vectorizer\",\"9_jun_1130am_vectorizer.pkl\",\"--weights\",\"9_jun_1130am_weights\"]\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_HP_DATA=small_fwaf.csv\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_HP_WEIGHTS=9_jun_1130am_weights\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_HP_VECTORIZER=9_jun_1130am_vectorizer.pkl\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-ap-southeast-1-527655063528/tensorflow-training-2022-06-13-06-01-31-389/model\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python39.zip:/usr/local/lib/python3.9:/usr/local/lib/python3.9/lib-dynload:/usr/local/lib/python3.9/site-packages:/usr/local/lib/python3.9/site-packages/smdebug-1.0.14b20220520-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument-3.4.2-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument_cext-0.2.4-py3.9-linux-x86_64.egg\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m /usr/local/bin/python3.9 model_v1_vect.py --data small_fwaf.csv --epochs 1 --model_dir s3://sagemaker-ap-southeast-1-527655063528/tensorflow-training-2022-06-13-06-01-31-389/model --vectorizer 9_jun_1130am_vectorizer.pkl --weights 9_jun_1130am_weights\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Collecting botocore==1.26.4\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Downloading botocore-1.26.4-py3-none-any.whl (8.8 MB)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.8/8.8 MB 44.2 MB/s eta 0:00:00\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/site-packages (from botocore==1.26.4) (1.0.0)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/site-packages (from botocore==1.26.4) (1.26.9)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/site-packages (from botocore==1.26.4) (2.8.2)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.26.4) (1.16.0)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Installing collected packages: botocore\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Attempting uninstall: botocore\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Found existing installation: botocore 1.24.21\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Uninstalling botocore-1.24.21:\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Successfully uninstalled botocore-1.24.21\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m aiobotocore 2.3.3 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.26.4 which is incompatible.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Successfully installed botocore-1.26.4\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m WARNING: There was an error checking the latest version of pip.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:56.482714: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:56.482893: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:01:56.518155: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Train set = 6000\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Val set = 2000\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Test set = 2000\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m /usr/local/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m   warnings.warn(\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Model: \"sequential\"\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m _________________________________________________________________\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m  Layer (type)                Output Shape              Param #   \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m =================================================================\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m text_vectorization (TextVec  (None, 16520)            0         \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m  torization)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m dense (Dense)               (None, 256)               4229376   \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m                                                                  \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m  dense_1 (Dense)             (None, 1024)              263168    \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m                                                                  \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m  batch_normalization (BatchN  (None, 1024)             4096      \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m  ormalization)                                                   \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m                                                                  \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m  dropout (Dropout)           (None, 1024)              0         \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m                                                                  \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m  dense_2 (Dense)             (None, 1)                 1025      \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m                                                                  \n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m =================================================================\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Total params: 4,497,665\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Trainable params: 4,495,617\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Non-trainable params: 2,048\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m _________________________________________________________________\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m None\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m [2022-06-13 06:02:00.788 726b0e7a6ec0:38 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m /usr/local/lib/python3.9/site-packages/smdebug-1.0.14b20220520-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m /usr/local/lib/python3.9/site-packages/smdebug-1.0.14b20220520-py3.9.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m [2022-06-13 06:02:01.076 726b0e7a6ec0:38 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 1/47 [..............................] - ETA: 1:50 - loss: 0.7060 - recall_1: 0.6667 - accuracy: 0.4844\n",
      " 2/47 [>.............................] - ETA: 3s - loss: 0.6835 - recall_1: 0.8571 - accuracy: 0.6602\n",
      " 3/47 [>.............................] - ETA: 2s - loss: 0.6802 - recall_1: 0.9167 - accuracy: 0.6979\n",
      " 4/47 [=>............................] - ETA: 2s - loss: 0.6619 - recall_1: 0.9444 - accuracy: 0.7188\n",
      " 5/47 [==>...........................] - ETA: 2s - loss: 0.6494 - recall_1: 0.9259 - accuracy: 0.7500\n",
      " 6/47 [==>...........................] - ETA: 2s - loss: 0.6420 - recall_1: 0.9032 - accuracy: 0.7747\n",
      " 7/47 [===>..........................] - ETA: 2s - loss: 0.6303 - recall_1: 0.9118 - accuracy: 0.7879\n",
      " 8/47 [====>.........................] - ETA: 2s - loss: 0.6163 - recall_1: 0.9167 - accuracy: 0.8047\n",
      " 9/47 [====>.........................] - ETA: 2s - loss: 0.6066 - recall_1: 0.9211 - accuracy: 0.8177\n",
      "10/47 [=====>........................] - ETA: 2s - loss: 0.5944 - recall_1: 0.9302 - accuracy: 0.8297\n",
      "11/47 [======>.......................] - ETA: 2s - loss: 0.5845 - recall_1: 0.9348 - accuracy: 0.8409\n",
      "12/47 [======>.......................] - ETA: 2s - loss: 0.5742 - recall_1: 0.9375 - accuracy: 0.8503\n",
      "13/47 [=======>......................] - ETA: 2s - loss: 0.5659 - recall_1: 0.9400 - accuracy: 0.8570\n",
      "14/47 [=======>......................] - ETA: 2s - loss: 0.5604 - recall_1: 0.8889 - accuracy: 0.8616\n",
      "15/47 [========>.....................] - ETA: 2s - loss: 0.5514 - recall_1: 0.8772 - accuracy: 0.8672\n",
      "16/47 [=========>....................] - ETA: 1s - loss: 0.5386 - recall_1: 0.8889 - accuracy: 0.8735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/47 [=========>....................] - ETA: 1s - loss: 0.5308 - recall_1: 0.8857 - accuracy: 0.8782\n",
      "18/47 [==========>...................] - ETA: 1s - loss: 0.5224 - recall_1: 0.8889 - accuracy: 0.8832\n",
      "19/47 [===========>..................] - ETA: 1s - loss: 0.5145 - recall_1: 0.8933 - accuracy: 0.8861\n",
      "20/47 [===========>..................] - ETA: 1s - loss: 0.5042 - recall_1: 0.8875 - accuracy: 0.8906\n",
      "21/47 [============>.................] - ETA: 1s - loss: 0.4971 - recall_1: 0.8889 - accuracy: 0.8940\n",
      "22/47 [=============>................] - ETA: 1s - loss: 0.4890 - recall_1: 0.8824 - accuracy: 0.8974\n",
      "23/47 [=============>................] - ETA: 1s - loss: 0.4782 - recall_1: 0.8764 - accuracy: 0.9008\n",
      "24/47 [==============>...............] - ETA: 1s - loss: 0.4677 - recall_1: 0.8817 - accuracy: 0.9049\n",
      "25/47 [==============>...............] - ETA: 1s - loss: 0.4587 - recall_1: 0.8750 - accuracy: 0.9075\n",
      "26/47 [===============>..............] - ETA: 1s - loss: 0.4483 - recall_1: 0.8774 - accuracy: 0.9102\n",
      "27/47 [================>.............] - ETA: 1s - loss: 0.4376 - recall_1: 0.8761 - accuracy: 0.9126\n",
      "28/47 [================>.............] - ETA: 1s - loss: 0.4299 - recall_1: 0.8783 - accuracy: 0.9149\n",
      "29/47 [=================>............] - ETA: 1s - loss: 0.4231 - recall_1: 0.8525 - accuracy: 0.9162\n",
      "30/47 [==================>...........] - ETA: 1s - loss: 0.4145 - recall_1: 0.8516 - accuracy: 0.9182\n",
      "31/47 [==================>...........] - ETA: 0s - loss: 0.4063 - recall_1: 0.8496 - accuracy: 0.9206\n",
      "32/47 [===================>..........] - ETA: 0s - loss: 0.4001 - recall_1: 0.8440 - accuracy: 0.9221\n",
      "33/47 [====================>.........] - ETA: 0s - loss: 0.3950 - recall_1: 0.8435 - accuracy: 0.9235\n",
      "34/47 [====================>.........] - ETA: 0s - loss: 0.3870 - recall_1: 0.8387 - accuracy: 0.9249\n",
      "35/47 [=====================>........] - ETA: 0s - loss: 0.3790 - recall_1: 0.8408 - accuracy: 0.9266\n",
      "36/47 [=====================>........] - ETA: 0s - loss: 0.3719 - recall_1: 0.8375 - accuracy: 0.9282\n",
      "37/47 [======================>.......] - ETA: 0s - loss: 0.3672 - recall_1: 0.8344 - accuracy: 0.9291\n",
      "38/47 [=======================>......] - ETA: 0s - loss: 0.3596 - recall_1: 0.8363 - accuracy: 0.9307\n",
      "39/47 [=======================>......] - ETA: 0s - loss: 0.3534 - recall_1: 0.8382 - accuracy: 0.9325\n",
      "40/47 [========================>.....] - ETA: 0s - loss: 0.3472 - recall_1: 0.8380 - accuracy: 0.9338\n",
      "41/47 [=========================>....] - ETA: 0s - loss: 0.3416 - recall_1: 0.8270 - accuracy: 0.9348\n",
      "42/47 [=========================>....] - ETA: 0s - loss: 0.3366 - recall_1: 0.8270 - accuracy: 0.9362\n",
      "43/47 [==========================>...] - ETA: 0s - loss: 0.3314 - recall_1: 0.8238 - accuracy: 0.9373\n",
      "44/47 [===========================>..] - ETA: 0s - loss: 0.3262 - recall_1: 0.8223 - accuracy: 0.9384\n",
      "45/47 [===========================>..] - ETA: 0s - loss: 0.3219 - recall_1: 0.8168 - accuracy: 0.9392\n",
      "46/47 [============================>.] - ETA: 0s - loss: 0.3172 - recall_1: 0.8164 - accuracy: 0.9402\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.3128 - recall_1: 0.8095 - accuracy: 0.9412\n",
      "47/47 [==============================] - 6s 84ms/step - loss: 0.3128 - recall_1: 0.8095 - accuracy: 0.9412 - val_loss: 0.1446 - val_recall_1: 0.0870 - val_accuracy: 0.9685\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m /opt/ml/code/model_v1_vect.py:122: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m   yhat = model.predict_generator(X_test)\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Average malicious label in test (truth) = 0.03750000149011612\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Average malicious label in PREDICTIONS = 0.006000000052154064\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Accuracy of model: 0.969\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m F1_score of model: 0.276\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m auc_roc of model: 0.933\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m recall of model: 0.160\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:02:08.905445: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/0001/assets\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/0001/assets\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m Saved to /opt/ml/model/0001\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b |\u001b[0m 2022-06-13 06:02:11,837 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36ms7xk7bn6qm-algo-1-ka25b exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "tf_estimator.fit(s3_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81398c2",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "719dd6ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ngwaf-test-2022-06-13-06-02-21'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "tf_endpoint_name = 'ngwaf-test-'+time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "tf_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ef563ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-southeast-1-527655063528/tensorflow-training-2022-06-13-06-01-31-389/model.tar.gz'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fb7677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class sagemaker.tensorflow.serving.Model has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "# For serving \n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "\n",
    "tf_serving_model = TensorFlowModel(\n",
    "    model_data = tf_estimator.model_data,\n",
    "    role=role,\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "predictor = tf_serving_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.c5.large',\n",
    "    endpoint_name=tf_endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a0038bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tf_predictor = tf_estimator.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.c5.large', # small one\n",
    "#     endpoint_name=tf_endpoint_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78639665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ngwaf-test-2022-06-13-06-02-21'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2701c0b",
   "metadata": {},
   "source": [
    "To test we need to convert the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3f27643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from utils_v1 import split_sentence\n",
    "from urllib.parse import unquote\n",
    "\n",
    "def prepare_input(dataset, x_raw_col='sentence', y_col='label'):\n",
    "    # Clean and split tokens\n",
    "    X_clean = dataset[x_raw_col].apply(lambda x: unquote(x))\n",
    "    X_clean = X_clean.apply(lambda x: split_sentence(x)) \n",
    "    # Need to join into sentence separated by space\n",
    "    X_clean = [\" \".join(row) for row in X_clean]\n",
    "    X_train = np.array([[string] for string in X_clean]) # each string needs to be in its own list\n",
    "    y_train = np.array(dataset[y_col])\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "test_data = pd.read_csv('pretrained/small_fwaf.csv')\n",
    "vectorizer = joblib.load('pretrained/9_jun_1130am_vectorizer.pkl')\n",
    "\n",
    "X_test, y_test = prepare_input(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0872b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(X_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3101e9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [[0.0838255]]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(['hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48953c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['103886'],\n",
       "       ['rcanimal'],\n",
       "       ['458010b88d9ce'],\n",
       "       ['cclogovs'],\n",
       "       ['using localization']], dtype='<U146')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a530a120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [[0.0860777795],\n",
       "  [0.0860777795],\n",
       "  [0.0860777795],\n",
       "  [0.0860777795],\n",
       "  [0.0851027668]]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac4403",
   "metadata": {},
   "source": [
    "## Proceed to go to `lambda` and input the endpoint name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b6e0379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ngwaf-test-2022-06-13-06-02-21'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457192cf",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "08d1a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a38a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
